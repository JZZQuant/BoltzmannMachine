{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0, cost is  -40065.3\n",
      "Training epoch 1, cost is  -58198.8\n",
      "Training epoch 2, cost is  -7483.06\n",
      "Training epoch 3, cost is  -796.907\n",
      "Training epoch 4, cost is "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import timeit\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import os\n",
    "from rbm import RBM\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "from kaggle import load_data\n",
    "\n",
    "learning_rate=0.0001\n",
    "training_epochs=10\n",
    "batch_size=3008\n",
    "n_hidden=50\n",
    "\n",
    "datasets = load_data()\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "l_train_x, l_train_y = datasets[1]\n",
    "l_test_x, l_test_y = datasets[2]\n",
    "predict_x, predict_y = datasets[3]\n",
    "\n",
    "# compute number of minibatches for training, validation and testing\n",
    "n_train_batches = train_set_x.shape.eval()[0]// batch_size\n",
    "# allocate symbolic variables for the data\n",
    "index = T.lscalar()    # index to a [mini]batch\n",
    "x = T.matrix('x')  # the data is presented as rasterized images\n",
    "\n",
    "rng = numpy.random.RandomState(123)\n",
    "theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "\n",
    "# initialize storage for the persistent chain (state = hidden\n",
    "# layer of chain)\n",
    "persistent_chain = theano.shared(numpy.zeros((batch_size, n_hidden),\n",
    "                                             dtype=theano.config.floatX),\n",
    "                                 borrow=True)\n",
    "\n",
    "# construct the RBM class\n",
    "rbm = RBM(input=x, n_visible=369,\n",
    "          n_hidden=n_hidden, numpy_rng=rng, theano_rng=theano_rng)\n",
    "# get the cost and the gradient corresponding to one step of CD-15\n",
    "cost, updates = rbm.get_cost_updates(lr=learning_rate,\n",
    "                                     persistent=persistent_chain, k=15)\n",
    "\n",
    "#################################\n",
    "#     Training the RBM          #\n",
    "#################################\n",
    "\n",
    "# start-snippet-5\n",
    "# it is ok for a theano function to have no output\n",
    "# the purpose of train_rbm is solely to update the RBM parameters\n",
    "train_rbm = theano.function(\n",
    "    [index],\n",
    "    cost,\n",
    "    updates=updates,\n",
    "    givens={\n",
    "        x: train_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "    },\n",
    "    name='train_rbm'\n",
    ")\n",
    "\n",
    "plotting_time = 0.\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# go through training epochs\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    # go through the training set\n",
    "    mean_cost = []\n",
    "    for batch_index in range(n_train_batches):\n",
    "        mean_cost += [train_rbm(batch_index)]\n",
    "\n",
    "    print('Training epoch %d, cost is ' % epoch, numpy.mean(mean_cost))\n",
    "    if abs(numpy.mean(mean_cost) ) <2 :\n",
    "        break\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "\n",
    "pretraining_time = (end_time - start_time) - plotting_time\n",
    "\n",
    "print ('Training took %f minutes' % (pretraining_time / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "l_train_=np.asarray(T.nnet.sigmoid(T.dot(l_train_x,rbm.W)).eval())\n",
    "l_test_=np.asarray(T.nnet.sigmoid(T.dot(l_test_x,rbm.W)).eval())\n",
    "predict_=np.asarray(T.nnet.sigmoid(T.dot(predict_x,rbm.W)).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5014433626081084"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(l_train_,np.asarray(l_train_y.eval()))\n",
    "test_y=clf.predict(l_test_)\n",
    "\n",
    "roc_auc_score(np.asarray(l_test_y.eval()), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2057.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.asarray(l_train_y.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04178226,  0.05218485, -0.02463629, ...,  0.04178226,\n",
       "        0.04178226,  0.04178226])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
